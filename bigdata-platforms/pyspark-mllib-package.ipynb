{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning in Spark\n",
    "========\n",
    "\n",
    "## Data Types\n",
    "\n",
    "  MLLIB support RDD of numpy arrays, vectors, matrices, labeled points.\n",
    "  \n",
    "  \n",
    "  Supported Distributed Vectors:\n",
    "  * dense vectors  \n",
    "  * sparse vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext \n",
    "sc = SparkContext('local','example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "x = Vectors.dense([1,2,3,4])\n",
    "\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[DenseVector([1.0, 2.0, 3.0, 4.0, 5.0])],\n",
       " [DenseVector([6.0, 7.0, 8.0, 9.0, 10.0])]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [Vectors.dense([1,2,3,4,5]), Vectors.dense([6,7,8,9,10])]\n",
    "\n",
    "xrdd = sc.parallelize(x, 2)\n",
    "\n",
    "xrdd.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Labeled Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  1.0\n",
      "Feature Vector:  [2.0,-1.0,4.0]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint as LP\n",
    "\n",
    "pt = LP(1, Vectors.dense(2,-1,4))\n",
    "\n",
    "print(\"Label: \", pt.label)\n",
    "print(\"Feature Vector: \", pt.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Creating a Word-count RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLLIB Classification Package\n",
    "\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    " * NB.train(Xrdd_train)\n",
    " * NB.train(Xrdd_test.features)\n",
    " * model.theta returns $\\log P(\\text{attribute | class})$\n",
    " * model.pi returns $\\log$ of class priors $\\log (\\text{class})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pysparl.mllib.classification import NaiveBayes as NB\n",
    "\n",
    "nbmodel = NB.train(Xrdd_train)\n",
    "\n",
    "testpred = NB.train(Xrdd_test.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainpred = nbmodel.predict(Xrdd_train.features)\n",
    "\n",
    "cf_mat [Xrdd_train.label][trainpred] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "model.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import DecisionTree\n",
    "\n",
    "dtmodel = DecisionTree.trainClassifier(Xrdd_train, \n",
    "                                       numClasses = 2,\n",
    "                                       impurity = 'entropy', ## options: gini or entropy\n",
    "                                       maxDepth = 5,\n",
    "                                       maxBins = 32,\n",
    "                                       minInstancesPerNode = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
