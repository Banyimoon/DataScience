{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce Framework\n",
    "===\n",
    "\n",
    "MapReduce is a programming model designed for proccesing massive datasets.  Originally, MapReduce was developed at Google.  The design of MapReduce framwork has inherit capability for distribued computing, which is necessary for big data applications.  MapReduce software is a proprietary software owned by Google, so we cannot use it for free, however, Hadoop is an open-source implementation of MapReduce, part of Apache project, and can be obtained for free.  \n",
    "\n",
    "Dealing with big data requires using large number of computing resources, and such resources should be fault tolerant (reliable), so that if one machine fails, it should not affect the stored data, not it should affect the computation.  The idea behind MapReduce model to solve this problem yet keeping the hardware cost reasonable is to use a large number of commodpty PCs for computation and distrinute the data and computations. For storage, the data files are divided into smaller chunks and each chunk is replicated among multiple nodes (PCs). As a result, if one node containing chuck B fails, there existing other replicas of the same chunk.  So, we can see that there are a lot of things happening behind the scene, however, when working with Hadoop, we don't see or bother with those details, because Hadoop takes care of those for us and hides those details.  Therefore, we can focus on our fascinating data analysis.\n",
    "\n",
    "On the othe hand, writing a H\n",
    "\n",
    "There are two fundamental steps\n",
    "\n",
    " **1. Map step**\n",
    "\n",
    "\n",
    "\n",
    " ** 2. Reduce step**\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "------------------------------------------------------------\n",
    "\n",
    "\n",
    "**Question:** What is the difference between MapReduce and Hadoop?\n",
    "\n",
    "**Answer:** Hadoop and MapReduce are both distributed programming models for processing large data files. MapReduce software is a proprietray software, but Hadoop is an open-source implementation as part of Apache project. \n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    " ### Wordcount\n",
    " **Problem definition:** Given a a set of large documents, count the frequency of each word that appears in all the documents.\n",
    " \n",
    " * **Mapper Input:** each mapper takes these in these documents\n",
    " \n",
    " * **Mapper Function:** apply some text processing, such as converting everything to lower-case, and tokenize the text by spliting based on space characte.\n",
    " \n",
    " * **Mapper Output:** after splitting the text, produces key value pairs, where the key is each word, and the value is just 1. \n",
    " \n",
    "  * ***E.g.*** Assume that we have 3 mappers, and the input to these mappers are as follows\n",
    " \n",
    "    Mapper 1: “Master Kenobi, you disappoint me.”\n",
    "    \n",
    "    Mapper 2: “Yoda holds you in such high esteem.\"\n",
    "    \n",
    "    Mapper 3: “Surely you can do better!” \n",
    " \n",
    " \n",
    "| Mapper 1 <br> key : value| Mapper 2 <br> key : value| Mapper 3 <br> key : value|\n",
    "|:--|:--|:---|\n",
    "|master:1 |yoda|surely:1|\n",
    "|kenobi:1|holds:1|you:1|\n",
    "|you:1|you:1|can:1|\n",
    "|disappoint:1|in:|do:1|\n",
    "|me:1|such:1|better:1|\n",
    "||high:1||\n",
    "||esteem:1||\n",
    "\n",
    "\n",
    " \n",
    " -----\n",
    " ### Movies \n",
    "\n",
    " \n",
    " ### Amazon purchases\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
