{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood Estimate\n",
    "\n",
    " * : $$\\theta^{*} = arg \\max_{\\theta} \\prod_i p(y_i =c \\vert \\mathbf{x}_i) \\\\ = arg \\max_{\\theta} \\sum_i -\\log p(y_i =c \\vert \\mathbf{x}_i) \\\\ $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Gradients\n",
    "\n",
    "$$\\frac{\\partial l}{\\partial \\theta} = \\left[\\frac{\\partial l}{\\partial \\mathbf{W}^1},\\frac{\\partial l}{\\partial b^1},...,\\frac{\\partial l}{\\partial \\mathbf{W}^L},\\frac{\\partial l}{\\partial b^L}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Risk Minimization\n",
    "\n",
    " * **Optimization Problem**\n",
    " \n",
    " * **Taylor Series Expansion**\n",
    " \n",
    " $$f(\\mathbf{x}) \\approx f(\\mathbf{x}_0) + ..$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "  * Descent direction: $-\\frac{\\partial f}{\\partial x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Procedure:\n",
    "\n",
    " * Initialize\n",
    " * Move in the direction of    \n",
    "   $\\theta = \\theta - \\alpha $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method: Second Order Gradient Descent\n",
    "\n",
    " $$\\mathbf{x} = \\mathbf{x}_0 + \\left[\\nabla_{\\mathbf{x}}^2 f(\\mathbf{x}_0)\\right]^{-1} \\nabla_\\mathbf{x} f(\\mathbf{x}_0)$$\n",
    " \n",
    " **Intuition:** $\\Rightarrow $ adpative steps\n",
    " \n",
    " Hesian matrix captures whtehr the contours are circles or elipses. Hesian, will squish elipises to circles.\n",
    " \n",
    " (put picture of circled contours vs. elipse contours)\n",
    " \n",
    "   * **Adapting how much I should move in each direction.**\n",
    "   * Along the directions woth large variance, we should adopt larger steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local and Global Optima\n",
    "\n",
    "\n",
    " * Critical points: $\\mathbf{x}\\in \\mathbb{R}^d\\vert \\nabla_x f(x) = 0$\n",
    " * Curvature in direction $v$ is : $v^T\\ \\nabla_x^2 f(x)\\ v$\n",
    " \n",
    " * Types of local minima:\n",
    "   * local minima:\n",
    "   * local maxima:\n",
    "   * saddle point:   \n",
    "    Moving along some direcitons, the funcion is increasing, and along some other ones, the function is decreasing. So, we don't know in which direction to move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points to consider \n",
    "\n",
    " * Deep networks do not have a single global optimum\n",
    "  \n",
    " * Hihly non-convex optimization problem\n",
    "   * can permute hidden units and the connections to achieve the same function \n",
    "   * hidden unit parameters are not identifiable\n",
    "   \n",
    " * Optimization is often stuck at local minimum or plateau (and saddle points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants of Gradient Descent\n",
    "\n",
    " * Batch Gradient Descent\n",
    " \n",
    " \n",
    " * Stochastic Gradient Descent\n",
    "   * just using one sample at a time\n",
    " \n",
    " * Mini-Batch Gradient Descent\n",
    "   * somewhere in between\n",
    "   * using some number of samples\n",
    "   \n",
    "   \n",
    "**Intuition:** \n",
    " * the first one, we update the parmateers after visiting all the samples. \n",
    "   * This results in accurate derivatives, but slow.\n",
    " \n",
    " * in the second case, we update the parameters y computing the derivative using only one sample. The idea is that on average, the computed derivatives should be (roughly) the same.\n",
    "  * This results in inaccurate derivatives, \n",
    " \n",
    " * Mini-Batch is a trade-off between the accurate derivatives and speed of computation.\n",
    " \n",
    "Almost always, we should use mini-batch:\n",
    "\n",
    " * The function is non-convex, so there is ***no \"right direction\"***. \n",
    " * With mini-batch, we can jump out of local minima.     \n",
    "   In every iteration, we use a different subset of samples to compute derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient Descent\n",
    "\n",
    "Idea: remembering the previous direction\n",
    "\n",
    " $$v_t = \\gamma v_{t-1} + \\alpha \\nabla_\\theta J(\\theta)$$\n",
    " \n",
    " $$\\theta_t = \\theta_{t-1} - v_t$$\n",
    " \n",
    "In Nesterov's method, the order in which we move and take the derivative is different:\n",
    "  * First move,\n",
    "  * the take the gradient\n",
    " \n",
    "Nesrerov showed that this method converges as quickly as second order approximation.\n",
    "\n",
    " Comparing number of iterations:   \n",
    "  if $\\epsilon = \\|f(x) - f(x^*)\\|$ where $x^*$ is the true optima\n",
    "   * $\\#\\text{ of iter} = \\frac{1}{\\epsilon}$  \n",
    "   * $\\#\\text{ of iter} = \\frac{1}{\\sqrt \\epsilon}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adpative Learning Rate\n",
    "\n",
    "We need differnet learning rate for each parameter.\n",
    "\n",
    "Idea: Slow down paramaters that are fast changing, speed up slow changing parameters.\n",
    "\n",
    " $$\\theta_{t+1,i} = \\theta_{t,i} - \\frac{\\alpha}{\\sqrt{G_{ii} + \\epsilon}} \\nabla_\\theta J(\\theta_{t,i})$$\n",
    " \n",
    "where $G_{ii}$ is a diagonal matrix: $G_{ii}^t = G_{ii}^{t-1} + \\left(\\nabla_\\theta J(\\theta_i)^t\\right)^2$\n",
    "\n",
    " $$\\theta_{t+1} = \\theta_{t} - \\frac{\\alpha}{\\sqrt{G_{t} + \\epsilon}} \\nabla_\\theta J(\\theta_{t})$$\n",
    " \n",
    "Now, we have a new problem. This way, we accumulate and eventually, the learning rate becomes very small. \n",
    " * Solution: as we go further waya in time, we forget the very old $G$. This insures that $G$ does not become very big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSProp:\n",
    "\n",
    "\n",
    "#### Adadelta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between RMSProp and Adadelta is that, the parameter units in RMSProp are lost, so Adadelta tries to fix that.\n",
    "\n",
    " * Gradients at time $t$: $g^t$\n",
    " * $G = gg^T$ but we only need the diagonal elements of $G$, which are $G_{ii}$\n",
    " * $G_{ii} = \\sum_t^T {(g_{ii}^t)}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Moment Estimtion (ADAM)\n",
    "\n",
    "$$\\mathbf{m}_t = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD with Noise:\n",
    "\n",
    "Add a small Gaussian noise to the parmaters in each iteration.\n",
    "\n",
    "$$\\theta = $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covaraince Matrix Adaptation Evolution Strategy (CMA-ES)\n",
    "\n",
    " **Gradient Free Optimization**\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0rc4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
