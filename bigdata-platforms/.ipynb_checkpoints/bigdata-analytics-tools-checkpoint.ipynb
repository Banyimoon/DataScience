{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big Data Analytic Tools\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Hadoop?\n",
    "\n",
    "Apache Hadoop is an open source programming framework designed for sotring as well as analyzing and processing very large datasets. \n",
    "\n",
    "cluster of commodity hardware. \n",
    "\n",
    "Created by Doug Cutting and Mike Cafarella 2005\n",
    "\n",
    "**Moving computaiton to data**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Commodity PCs: the difference between HPC and Hadoop cluster.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figs/hadoop/distributed-data.png\" width=500></img>\n",
    "\n",
    "\n",
    "Compute nodes and storage nodes are the same\n",
    "\n",
    "\n",
    " * Cheap architecture\n",
    " * Scailibility\n",
    " * Reliability (handling node failures)\n",
    "\n",
    "\n",
    "Data Analysis Limitation: Having this framework allows us to use massive data sets. But the the type of analysis is a bit different. In machine learning, you may have a relatively small dataset and perform very complex analysis on them. Using Hadoop, allows us to use tremendous amount of data, but there is a limitation imposed on complexity of analysis.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " **HBASE**: uses HDFS and MapReduce to organize data by columns\n",
    "\n",
    " **HIVE**: uses a meta store to apply schema information, to provide sql-like interface\n",
    "\n",
    " **PIG**: a scirpting language, providing more flexibility than SQL\n",
    "\n",
    " **SPARK**: a more general engine for programming with interface to HDFS, replacing MapReduce\n",
    "\n",
    " **SPLUNK**: focused on machine generated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HBASE\n",
    "\n",
    " Read and write to HDFS, read and write directly from user interface\n",
    " \n",
    " Key-value store, length of values can vary\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HIVE\n",
    "\n",
    "  A higher level data processing language\n",
    "\n",
    "  Managing strutured and unstructured data\n",
    "\n",
    "  Provess queries in a SQL-like language\n",
    "  \n",
    "  First developed at Facebook, now is an Apache software\n",
    "  \n",
    "  Features:\n",
    "    * OLAP (online analytical processing)\n",
    "    * SQL-like language for queries (HiveQL or HQL)\n",
    "    * Provides data warehouse infrastructure for hadoop\n",
    "    \n",
    "\n",
    "  Different data units:\n",
    "  \n",
    "  1. Tables: maps to HDFS directories\n",
    "  2. Partitions: maps to sub-directories under tables\n",
    "  3. Buckets: maps to files under each partition\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIVE data structures:\n",
    "\n",
    " * Associative arrays (map < key-type, value-type >)\n",
    " * Lists (list < element type >)\n",
    " * Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
