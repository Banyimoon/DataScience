{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pig Progrmming for Big Data\n",
    "====\n",
    "\n",
    "Pig is a high-level platform, to extend data processing with Hadoop MapReduce. Pig's language is called **Pig Latin**. Pig is a suitable tool for computing summry statistics from data. \n",
    "\n",
    "\n",
    "Pig can be exeuted in two modes:\n",
    " * local mode: runs on a single JVM and can only access the local filesystem\n",
    " * distributed mode: runs on a Hadoop cluster, accessing HDFS, and translates queries into MapReduce jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pig Latin:**\n",
    "\n",
    "* Interacting with HDFS\n",
    "* Mainpulate data that is sitting on HDFS\n",
    "\n",
    "Pig performs data processing in a directed acyclic graph (DAG) where each node represents an operation (alias) applied to the data. Such operations consists of two types\n",
    "\n",
    " 1. Relation algebra operations like join, filter, project\n",
    " 2. Functional programming style operations such as map, reduce, etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running pig\n",
    "\n",
    "* **Using the interactive shell called *grunt***\n",
    "\n",
    "   * Running pig on local mode:   `pig -x local`  \n",
    "   * Running on distributed mode: `pig -x mapreduce`\n",
    "\n",
    "* **Execute a pig script from command line** *E.g. `pig myscript.pig`*  \n",
    "\n",
    "* **Embed your pig query into a Java program**\n",
    "\n",
    "  * Write the java program for your application\n",
    "  * Compile the program \n",
    "  * Execute the program \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grunt interactive shell commands\n",
    "\n",
    "* `grunt> exec myscript.pig`  execute in a separate forked process\n",
    "* `grunt> run myscript.pig`   run in the same process\n",
    "\n",
    "Grunt also recognizes UNIX shell commands:\n",
    "\n",
    "* `grunt> ls `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pig Latin\n",
    "\n",
    "A high level overview:\n",
    "* Read/write from/to HDFS\n",
    "* Data types\n",
    "* Diagnostic\n",
    "* Expressions and functions\n",
    "* Relational operations (UNION, JOIN, FILTER, etc)\n",
    "* No supporting command for insert, delete, update\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pig Latin Workflow\n",
    "\n",
    "Writing Pig scripts to process data: \n",
    " * Load data from local/HDFS into a new alias `alias = LOAD \"filename\" AS (...);`\n",
    " * Manipulate the data usin relation operations\n",
    "   * For each operation/step create a new alias `new_alias = pig_operation(old_alis);`\n",
    " * Dump the final alis to display the output, or store in HDFS/local directory `DUMP resut_alias;`\n",
    "\n",
    "Comments in a Pig script are denoted by \"--\".\n",
    "\n",
    "\n",
    "\n",
    "* Load data into an alias  \n",
    "\n",
    "```pig\n",
    "-- alias = LOAD filename AS (..);\n",
    "alias = LOAD 'input.txt' AS (attr1, attr2);\n",
    "\n",
    "-- comma separate values   \n",
    "-- mydata = LOAD filename USING PigStorage(',') ..;  \n",
    "mydata = LOAD 'input.txt'   \n",
    "         USING PigStorage(',')   \n",
    "         AS (attr1, attr2, ..);   \n",
    "```\n",
    "\n",
    "\n",
    "* Manipulate the alias using relational operations\n",
    "\n",
    "```pig\n",
    "\n",
    "```\n",
    "\n",
    "If you don't specify the name of attributes, they will be defined by `$0, $1, $2, ..`\n",
    "\n",
    "#### Comparing SQL and Pig \n",
    "\n",
    "Although, the syntax of Pig latin is different than SQL, but the workflow of the two are quite similar.\n",
    "\n",
    "**SQL**\n",
    "\n",
    "```sql\n",
    "-- display username and address of those with age>30\n",
    "Select Username,Address \n",
    "From UserTable\n",
    "Where Age>30;\n",
    "```\n",
    "\n",
    "**Pig**\n",
    "\n",
    "```pig\n",
    "-- step 1: load the data\n",
    "UserTable = LOAD 'usertable.txt' USING PigStorae(',') AS (Username:chararray, Address:chararray);\n",
    "-- step 2: filter the dataset based on age>30\n",
    "Subset = FILTER UserTable BY age > 30;\n",
    "-- step 3: display the output\n",
    "DUMP Subset;\n",
    "```\n",
    "\n",
    "### Pig Read-Write Operations\n",
    "\n",
    "|Operation | Description |\n",
    "|:--:|:--|\n",
    "|LOAD |Load data in a file. `Usage: alias = LOAD 'filename' [USING function] [AS schema];`|\n",
    "|LIMIT|Limit the number of tuples in a given alias. `Usage: alias = LIMIT old_alias n;`|\n",
    "|DUMP |Display the content of an alias. `Usage: DUMP alias;`|\n",
    "|STORE|Store the content of an alias into a directory. `Usage: STORE alias INTO 'directory' [USING function];`|\n",
    "\n",
    "### Defining Table Schema \n",
    "\n",
    "```pig\n",
    "alias = LOAD 'filename' [USING function] [AS schema];\n",
    "```\n",
    "\n",
    " * By default, Pig assumes columns/fields are separated by tabs.\n",
    " * Use the built-in function *PigStorage()* to specify the separator\n",
    " * Define the schema, attribute names and their types \n",
    " \n",
    "##### Example:  \n",
    "\n",
    "We have the following input file, attribues are comma-separated, \n",
    "\n",
    "```pig\n",
    "mydata = LOAD 'filename' USING PigStorage(',') AS ();\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example workflow\n",
    "\n",
    "```pig\n",
    "data = LOAD '/user/hduser/wikipedia/wiki_edits/txt' \n",
    "       USING PigStorage(',')\n",
    "       AS (rev, aid, rid, article, ts, uname, uid);\n",
    "       \n",
    "grp = GROUP data BY article; -- output has two columns: group,data\n",
    "\n",
    "counts = FOREACH grp GENERATE group, COUNT(data);\n",
    "\n",
    "results = LIMIT counts 4;\n",
    "DUMP results;\n",
    "\n",
    "STORE counts INTO 'output.txt' USING PigStorage(',');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic Data Types\n",
    "\n",
    "|Data Types | |\n",
    "|:--:|:--:|\n",
    "| int ||\n",
    "| long ||\n",
    "| float ||\n",
    "| double ||\n",
    "| chararray ||\n",
    "| bytearray ||\n",
    "\n",
    "```pig\n",
    "data = LOAD 'input.txt' \n",
    "       USING PigStorage(',')\n",
    "       AS (rev:chararray, aid:int, ..);\n",
    "```\n",
    "\n",
    "If you don't specify the type, the attributes will be of type *bytearray*, the most generic data type.\n",
    "\n",
    "#### More complex data types\n",
    "\n",
    "|Complex Data Types | |\n",
    "|:--:|:--:|\n",
    "| Tuple ||\n",
    "| Bag ||\n",
    "| Map ||\n",
    "\n",
    "```\n",
    "$ hadoop fs -cat data.txt\n",
    "(1,2,3) (4,5,6)\n",
    "(4,5,3) (3,3,2)\n",
    "```\n",
    "\n",
    "```pig\n",
    "grunt> A = LOAD 'data.txt' \n",
    "           AS (t1:tuple(t1a:int, t1b:int, t1c:int),\n",
    "               t2:tuple(t2a:int, t2b:int, t2c:int));\n",
    "                               \n",
    "DUMP A;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Relational Operations in Pig\n",
    "\n",
    "\n",
    " * FOREACH\n",
    " * FILTER \n",
    " * ORDER BY\n",
    " * SPLIT \n",
    " * UNION\n",
    " * DISTINCT\n",
    " * GROUP\n",
    " * JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FOREACH\n",
    "\n",
    "```pig\n",
    "grades = LOAD 'greades.txt' \n",
    "         USING PigStorage(',')\n",
    "         AS (name:chararray, hw1:int, hw2:int, hw3:int);\n",
    "         \n",
    "hwtotals = FOREACH grades GENERATE name, hw1+hw2+hw3;\n",
    "\n",
    "DUMP hwtotals;\n",
    "```\n",
    "The result will be:\n",
    "\n",
    "```\n",
    "(Alex,67)\n",
    "(John,79)\n",
    "(Lee,73)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming a column vector:\n",
    "\n",
    "```pig\n",
    "titels = FOREACH movies GENERATE $1 AS title;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Regular Expressions to extract fields:\n",
    "\n",
    "Assume the input is given as \n",
    "```\n",
    "Samsung TV (499.99)\n",
    "iPhone 6s (650.00)\n",
    "\n",
    "```\n",
    "and we wat to extract the item names, which is everything from the begining of the line upto the openning paranthesis \"(\"\n",
    "\n",
    "```pig\n",
    "REGEXP_EXTRACT \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTER\n",
    "\n",
    "\n",
    "Equivalent to *WHERE* clause in SQL:\n",
    "```sql\n",
    "SELECT columns FROM tablename\n",
    "WHERE expression;\n",
    "```\n",
    "Pig syntax: `FILTER tablename BY expression`\n",
    "```pig\n",
    "filtered_result = FILTER tablename BY exoression;\n",
    "```\n",
    "\n",
    "Exmaple:\n",
    "```pig\n",
    "best = FILTER  hwtotals BY $1 > 80;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORDER BY\n",
    "\n",
    "Pig syntax:\n",
    "```pig\n",
    "sorted_result = ORDER tablename BY column1 DESC [, column2 ASC];\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```pig\n",
    "result = ORDER hwtotals BY name ASC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPLIT\n",
    "\n",
    "Splits a table into two based on a condition.\n",
    "\n",
    "SQL equivalnce:\n",
    "```sql\n",
    "SELECT T1 \n",
    "```\n",
    "\n",
    "Pig syntax\n",
    "```pig\n",
    "split_alias = SPLIT tablename \n",
    "              INTO t1 IF col1>s,\n",
    "                   t2 IF col1<=s;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNION\n",
    "\n",
    "To obtain union of two tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISTINCT\n",
    "\n",
    "```pig\n",
    "uniqs = DISTINCT dups;\n",
    "```\n",
    "In pig, distinct is applied to a table, not to an exression (as is done in SQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GROUP\n",
    "\n",
    "Syntax:\n",
    "```pig\n",
    "grp = GROUP tablename BY colum1;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "```pig\n",
    "\n",
    "data = LOAD 'data.txt' \n",
    "       USING PigStorage(',') \n",
    "       AS(name:chararray, score:int);\n",
    "\n",
    "grps = GROUP data by name;\n",
    "\n",
    "totalscores = FOREACH grps \n",
    "              GENERATE group AS name,\n",
    "                       SUM(data.$1) AS total;\n",
    "                       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GROUP ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JOIN\n",
    "\n",
    "```pig\n",
    "alias = JOIN table1 BY col1, table2 BY col2;\n",
    "```\n",
    "\n",
    "###### Example:\n",
    "\n",
    "```pig\n",
    "grades = LOAD 'grades.txt' USING PigStorage(',') \n",
    "         AS (name:chararray, hw1:int, hw2:int, hw3:int);\n",
    "\n",
    "majors = LOAD 'majors.txt' USING PigStorage(',') \n",
    "         AS (name:chararray, dept:chararray);\n",
    "\n",
    "transcript = JOIN majors BY name, grades BY name;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Functions in Pig\n",
    "\n",
    " * AVG\n",
    " * CONCAT\n",
    " * COUNT\n",
    " * DIFF\n",
    " * MAX\n",
    " * MIN\n",
    " * SIZE\n",
    " * SUM\n",
    " * TOKENIZE\n",
    " * FLATTEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOKENIZE\n",
    "\n",
    "```pig\n",
    "FOREACH docs GENERATE TOKENIZE($0) AS words;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLATTEN\n",
    "\n",
    "Convert the bag into a list\n",
    "\n",
    "```pig\n",
    "allwords = FOREACH wordsbag GENERATE FLATTEN (wordsba\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pig Macros\n",
    "\n",
    "To package reusable codes\n",
    "\n",
    "```pig\n",
    "DEFINE <macro> (<args>) RETURNS <returnvalue> {\n",
    "    write the pig latin codes for macro definition.\n",
    "}\n",
    "```\n",
    "\n",
    "##### Example\n",
    "\n",
    "```pig\n",
    "DEFINE wordcount(text) RETURNS counts {\n",
    "    tokens = FOREACH $text \n",
    "             GENERATE TOKENIZE($0) \n",
    "             AS terms;\n",
    "             \n",
    "    wordlist = FOREACH tokens \n",
    "               GENERATE FLATTEN(terms) \n",
    "               AS word, 1 AS freq;\n",
    "               \n",
    "    groups = GROUP wordlist BY word;\n",
    "    \n",
    "    $counts = FOREACH groups \n",
    "              GENERATE group \n",
    "              AS word, SUM(wordlist.freq) AS freq;\n",
    "}\n",
    "```\n",
    "\n",
    "Tokens: \n",
    "\n",
    "|terms : bags |\n",
    "|:---:|\n",
    "|{(a)(this)(that)}|\n",
    "|{(cat)(is))}|\n",
    "\n",
    "wordlist:\n",
    "\n",
    "|word | freq |\n",
    "|:---:|:---:|\n",
    "|a|1|\n",
    "|this|1|\n",
    "|that|1|\n",
    "\n",
    "groups:\n",
    "\n",
    "|group : |\n",
    "|:---:|:---:|\n",
    "|||\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pig User Defined Functions  \n",
    "\n",
    "Write your functions in Java.\n",
    "\n",
    "first make sure that the functio you are intending to write is not already written by the Pig community. Check piggybank repository.\n",
    "\n",
    "\n",
    "### Types of functions\n",
    " * #### Eval functions\n",
    "\n",
    " * #### Filter functions\n",
    "\n",
    " * #### Store/Load functions\n",
    "\n",
    "\n",
    "\n",
    "```java\n",
    "import java.io.*;\n",
    "import java.util.*;\n",
    "\n",
    "import org.apache.pig.FilterFunc; /* customizing FilterFunc */\n",
    "\n",
    "\n",
    "public class PopularTerms extends FilterFunc {\n",
    "    @override;\n",
    "    \n",
    "    public Boolean exec (Tuple tuple) throws IOException {\n",
    "        // this code will filter frequency below threshold\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Piggy bank\n",
    "\n",
    "A repositiry of Pig functions shared by the Pig community.\n",
    "\n",
    "To locate the repository, look for piggybank.jar file:\n",
    "\n",
    "```bash\n",
    "ls $PIG_HOME/contrib/piggybank/java\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Pig Programs Embedded in Java \n",
    "\n",
    "```java\n",
    "import java.io.IoException;\n",
    "import org.apache.pig.PigServer;\n",
    "\n",
    "public class idmapreduce {\n",
    "    public static void main(String[] args) {\n",
    "}\n",
    "```\n",
    "\n",
    "Compile:\n",
    "```\n",
    "javac -cp \\$PIG_HOME/pig-0.11.0.jar idmapreduce.java\n",
    "```\n",
    "\n",
    "Running:\n",
    "\n",
    "```\n",
    "java -cp \"..\" idmapreduce\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
