{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing with Pig and Hive\n",
    "====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "Select Username,Address \n",
    "From UserTable\n",
    "Where Age>30;\n",
    "```\n",
    "\n",
    "Pig:\n",
    "* Load UserTable;\n",
    "* For each row check w\n",
    "* Return the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pig Latin:\n",
    "* Interacting eith HDFS\n",
    "* Mainpulate data that is sitting on HDFS\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running pig\n",
    "\n",
    "Running pig on local mode: `pig -x local`  \n",
    "Running on distributed mode: `pig -x mapreduce`\n",
    "\n",
    "\n",
    "* Using the interactive shell called *grunt*\n",
    "* Execute a pig script *E.g. `pig myscript.pig`*\n",
    "* Embed your pig query into a Java program\n",
    "\n",
    "\n",
    "\n",
    "Pig scripts: \n",
    "* Comments are noted by \"--\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedded in Java\n",
    "\n",
    "```java\n",
    "import java.io.IoException;\n",
    "import org.apache.pig.PigServer;\n",
    "\n",
    "public class idmapreduce {\n",
    "    public static void main(String[] args) {\n",
    "}\n",
    "```\n",
    "\n",
    "Compile:\n",
    "```\n",
    "javac -cp \\$PIG_HOME/pig-0.11.0.jar idmapreduce.java\n",
    "```\n",
    "\n",
    "Running:\n",
    "\n",
    "```\n",
    "java -cp \"..\" idmapreduce\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grunt shell commands\n",
    "\n",
    "* `grunt> exec myscript.pig`  execute in a separate forked process\n",
    "* `grunt> run myscript.pig`   run in the same process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pig Latin\n",
    "\n",
    "A high leve\n",
    "Overview:\n",
    "* Read/write from/to HDFS\n",
    "* Data types\n",
    "* Diagnostic\n",
    "* Expressions and functions\n",
    "* Relational operations (UNION, JOIN, FILTER, etc)\n",
    "* No supporting command for insert, delete, update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pig Latin Workflow\n",
    "\n",
    "* Load data into an alias  \n",
    "\n",
    "```pig\n",
    "-- alias = LOAD filename AS (..);\n",
    "alias = LOAD 'input.txt' AS (attr1, attr2);\n",
    "\n",
    "-- comma separate values   \n",
    "-- mydata = LOAD filename USING PigStorage(',') ..;  \n",
    "mydata = LOAD 'input.txt'   \n",
    "         USING PigStorage(',')   \n",
    "         AS (attr1, attr2, ..);   \n",
    "```\n",
    "\n",
    "* Manipulate the alias using relational operations\n",
    "\n",
    "```pig\n",
    "\n",
    "```\n",
    "\n",
    "If you don't specify the name of attributes, they will be defined by `$0, $1, $2, ..`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example workflow\n",
    "\n",
    "```pig\n",
    "data = LOAD '/user/hduser/wikipedia/wiki_edits/txt' \n",
    "       USING PigStorage(',')\n",
    "       AS (rev, aid, rid, article, ts, uname, uid);\n",
    "       \n",
    "grp = GROUP data BY article; -- output has two columns: group,data\n",
    "\n",
    "counts = FOREACH grp GENERATE group, COUNT(data);\n",
    "\n",
    "results = LIMIT counts 4;\n",
    "DUMP results;\n",
    "\n",
    "STORE counts INTO 'output.txt' USING PigStorage(',');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atomic Data Types\n",
    "\n",
    "|Data Types | |\n",
    "|:--:|:--:|\n",
    "| int ||\n",
    "| long ||\n",
    "| float ||\n",
    "| double ||\n",
    "| chararray ||\n",
    "| bytearray ||\n",
    "\n",
    "```pig\n",
    "data = LOAD 'input.txt' \n",
    "       USING PigStorage(',')\n",
    "       AS (rev:chararray, aid:int, ..);\n",
    "```\n",
    "\n",
    "If you don't specify the type, the attributes will be of type *bytearray*, the most generic data type.\n",
    "\n",
    "#### More complex data types\n",
    "\n",
    "|Complex Data Types | |\n",
    "|:--:|:--:|\n",
    "| Tuple ||\n",
    "| Bag ||\n",
    "| Map ||\n",
    "\n",
    "```\n",
    "$ hadoop fs -cat data.txt\n",
    "(1,2,3) (4,5,6)\n",
    "(4,5,3) (3,3,2)\n",
    "```\n",
    "\n",
    "```pig\n",
    "grunt> A = LOAD 'data.txt' \n",
    "           AS (t1:tuple(t1a:int, t1b:int, t1c:int),\n",
    "               t2:tuple(t2a:int, t2b:int, t2c:int));\n",
    "                               \n",
    "DUMP A;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Relational Operators in Pig\n",
    "======\n",
    "\n",
    "\n",
    " * FOREACH\n",
    " * FILTER \n",
    " * ORDER BY\n",
    " * SPLIT \n",
    " * UNION\n",
    " * DISTINCT\n",
    " * GROUP\n",
    " * JOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FOREACH\n",
    "\n",
    "```pig\n",
    "grades = LOAD 'greades.txt' \n",
    "         USING PigStorage(',')\n",
    "         AS (name:chararray, hw1:int, hw2:int, hw3:int);\n",
    "         \n",
    "hwtotals = FOREACH grades GENERATE name, hw1+hw2+hw3;\n",
    "\n",
    "DUMP hwtotals;\n",
    "```\n",
    "The result will be:\n",
    "\n",
    "```\n",
    "(Alex,67)\n",
    "(John,79)\n",
    "(Lee,73)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming a column vector:\n",
    "\n",
    "```pig\n",
    "titels = FOREACH movies GENERATE $1 AS title;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Regular Expressions to extract fields:\n",
    "\n",
    "Assume the input is given as \n",
    "```\n",
    "Samsung TV (499.99)\n",
    "iPhone 6s (650.00)\n",
    "\n",
    "```\n",
    "and we wat to extract the item names, which is everything from the begining of the line upto the openning paranthesis \"(\"\n",
    "\n",
    "```pig\n",
    "REGEXP_EXTRACT \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTER\n",
    "\n",
    "\n",
    "Equivalent to *WHERE* clause in SQL:\n",
    "```sql\n",
    "SELECT columns FROM tablename\n",
    "WHERE expression;\n",
    "```\n",
    "Pig syntax: `FILTER tablename BY expression`\n",
    "```pig\n",
    "filtered_result = FILTER tablename BY exoression;\n",
    "```\n",
    "\n",
    "Exmaple:\n",
    "```pig\n",
    "best = FILTER  hwtotals BY $1 > 80;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ORDER BY\n",
    "\n",
    "Pig syntax:\n",
    "```pig\n",
    "sorted_result = ORDER tablename BY column1 DESC [, column2 ASC];\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```pig\n",
    "result = ORDER hwtotals BY name ASC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPLIT\n",
    "\n",
    "Splits a table into two based on a condition.\n",
    "\n",
    "SQL equivalnce:\n",
    "```sql\n",
    "SELECT T1 \n",
    "```\n",
    "\n",
    "Pig syntax\n",
    "```pig\n",
    "split_alias = SPLIT tablename \n",
    "              INTO t1 IF col1>s,\n",
    "                   t2 IF col1<=s;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNION\n",
    "\n",
    "To obtain union of two tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DISTINCT\n",
    "\n",
    "```pig\n",
    "uniqs = DISTINCT dups;\n",
    "```\n",
    "In pig, distinct is applied to a table, not to an exression (as is done in SQL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GROUP\n",
    "\n",
    "Syntax:\n",
    "```pig\n",
    "grp = GROUP tablename BY colum1;\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example:\n",
    "\n",
    "```pig\n",
    "\n",
    "data = LOAD 'data.txt' \n",
    "       USING PigStorage(',') \n",
    "       AS(name:chararray, score:int);\n",
    "\n",
    "grps = GROUP data by name;\n",
    "\n",
    "totalscores = FOREACH grps \n",
    "              GENERATE group AS name,\n",
    "                       SUM(data.$1) AS total;\n",
    "                       \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GROUP ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JOIN\n",
    "\n",
    "```pig\n",
    "alias = JOIN table1 BY col1, table2 BY col2;\n",
    "```\n",
    "\n",
    "###### Example:\n",
    "\n",
    "```pig\n",
    "grades = LOAD 'grades.txt' USING PigStorage(',') \n",
    "         AS (name:chararray, hw1:int, hw2:int, hw3:int);\n",
    "\n",
    "majors = LOAD 'majors.txt' USING PigStorage(',') \n",
    "         AS (name:chararray, dept:chararray);\n",
    "\n",
    "transcript = JOIN majors BY name, grades BY name;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
