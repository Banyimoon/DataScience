{
 "metadata": {
  "name": "",
  "signature": "sha256:5fbfc6affd2dfc8bc02fc55acf56049e1141fc16d3be701adab3086f10c80354"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Naive Bayes Classification in R\n",
      "==============\n",
      "\n",
      "**Vahid Mirjalili, Data Scientist**\n",
      "\n",
      "Table of Contents:\n",
      "\n",
      " [1. Preprocessing Steps: Getting and Cleaning Data](#getting-data)\n",
      "\n",
      "   * [Extracting Features and Class Labels](#extract-data)\n",
      "   * [Splitting Data into Training and Test Sets](#split-data)\n",
      "   * [Feature Scaling: Standardization](#feature-standard)\n",
      "   * [Dimensionality Reduction: PCA and LDA](#dimensionality-reduction)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"getting-data\">\n",
      "\n",
      "# 1. Preprocessing Steps: Getting and Cleaning Data\n",
      "\n",
      "</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Getting data from github\n",
      "require(RCurl)\n",
      "df.url <- getURL(\"https://raw.githubusercontent.com/rasbt/pattern_classification/master/data/iris.csv\")\n",
      "df <- read.csv(text = df.url, header=FALSE)\n",
      "\n",
      "head(df)\n",
      "levels(df$V5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "packageStartupMessage in packageStartupMessage(gettextf(\"Loading required package: %s\", : Loading required package: RCurl\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "packageStartupMessage in packageStartupMessage(gettextf(\"Loading required package: %s\", : Loading required package: bitops\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "   V1  V2  V3  V4          V5\n",
        "1 5.1 3.5 1.4 0.2 Iris-setosa\n",
        "2 4.9 3.0 1.4 0.2 Iris-setosa\n",
        "3 4.7 3.2 1.3 0.2 Iris-setosa\n",
        "4 4.6 3.1 1.5 0.2 Iris-setosa\n",
        "5 5.0 3.6 1.4 0.2 Iris-setosa\n",
        "6 5.4 3.9 1.7 0.4 Iris-setosa"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "[1] \"Iris-setosa\"     \"Iris-versicolor\" \"Iris-virginica\" "
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"extract-data\">\n",
      "\n",
      "## Extracting features and class labels\n",
      "\n",
      "</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_iris <- df[,1:4]\n",
      "\n",
      "y_iris <- factor(df$V5, labels=seq(length(levels(df$V5))))\n",
      "\n",
      "y_iris"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
        " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
        " [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
        "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
        "[149] 3 3\n",
        "Levels: 1 2 3"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"split-data\">\n",
      "\n",
      "## Splitting Data into Training and Test Sets\n",
      "\n",
      "</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_data <- function(df, ratio=0.7, seed=NULL) {\n",
      "    ## To split a dataframe into train & test sets\n",
      "    ## with given ratio and random seed\n",
      "    if (!is.null(seed)) set.seed(seed)\n",
      "    all_indx   <- 1:nrow(df)\n",
      "    train_indx <- sample(all_indx, size=ratio*nrow(df), replace=FALSE)\n",
      "    train_set  <- df[train_indx , ]\n",
      "    test_set   <- df[-train_indx, ]\n",
      "    return(list(trainset=train_set, testset=test_set))\n",
      "}\n",
      "\n",
      "splits <- split_data(df)\n",
      "\n",
      "## Show the number of training and test samples\n",
      "lapply(splits, nrow)\n",
      "\n",
      "X_train <- splits$trainset[,1:4]\n",
      "y_train <- splits$trainset[,5]\n",
      "X_test <- splits$testset[,1:4]\n",
      "y_test <- splits$testset[,5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "$trainset\n",
        "[1] 105\n",
        "\n",
        "$testset\n",
        "[1] 45\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"feature-standard\">\n",
      "\n",
      "## Feature Scaling: Standardization\n",
      "\n",
      "</a>\n",
      "\n",
      "**Standardize the data to have mean 0 and standrad deviation 1**\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Find the mean and sigma of features from training set\n",
      "train_mean <- apply(X_train, 2, mean)  # alternatively use colMeans()\n",
      "train_sd <- apply(X_train, 2, sd)\n",
      "train_mean\n",
      "train_sd\n",
      "\n",
      "X_train <- scale(X_train, center=TRUE, scale=train_sd)\n",
      "# alternative way: X_train <- t((t(X_train) - train_mean)/train_sd)\n",
      "\n",
      "X_test <- scale(X_test, center=train_mean, scale=train_sd)\n",
      "apply(X_test, 2, mean)\n",
      "apply(X_test, 2, sd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "      V1       V2       V3       V4 \n",
        "5.848571 3.074286 3.771429 1.212381 "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "       V1        V2        V3        V4 \n",
        "0.8309071 0.4085689 1.7776234 0.7715737 "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "         V1          V2          V3          V4 \n",
        "-0.02101356 -0.16550218 -0.02393065 -0.05924811 "
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "       V1        V2        V3        V4 \n",
        "0.9996470 1.1961024 0.9860024 0.9730207 "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a id=\"dimensionality-reduction\">\n",
      "\n",
      "## Dimensionality Reduction: PCA and LDA\n",
      "\n",
      "</a>\n",
      "\n",
      "**Applying Principal Component Analysis to new get features with highest variance, regardless of class labels**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pca.iris <- prcomp(X_train)\n",
      "\n",
      "print(pca.iris)\n",
      "\n",
      "X_train_pca <- pca.iris$x\n",
      "X_test_pca <- X_test %*% pca.iris$rotation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Standard deviations:\n",
        "[1] 1.7234321 0.9337837 0.3702724 0.1439723\n",
        "\n",
        "Rotation:\n",
        "          PC1        PC2        PC3        PC4\n",
        "V1  0.5226180 0.36329877  0.7259494 -0.2605414\n",
        "V2 -0.2873283 0.92626887 -0.2162334  0.1127456\n",
        "V3  0.5749223 0.04588400 -0.1485522  0.8033002\n",
        "V4  0.5601582 0.08907661 -0.6357458 -0.5235603\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Applying Linear Discriminant Analysis (LDA)**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "library(MASS)\n",
      "lda.iris <- lda(X_train, grouping=y_train)\n",
      "\n",
      "y_pred <- predict(lda.iris, X_test)$class\n",
      "\n",
      "error_rate <- sum(y_pred != y_test)/length(y_test)*100\n",
      "print(error_rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1] 2.222222\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}